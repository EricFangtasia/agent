# sensevoice_demo.py
import os
import warnings
import pyaudio
import wave
import tempfile
import threading
import time
import sys
import numpy as np
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œagentç›®å½•åˆ°sys.path
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
agent_dir = os.path.join(project_root, 'agent')
if project_root not in sys.path:
    sys.path.insert(0, project_root)
if agent_dir not in sys.path:
    sys.path.insert(0, agent_dir)

class SenseVoiceASR:
    def __init__(self, model_path=None):
        """åˆå§‹åŒ–SenseVoiceè¯­éŸ³è¯†åˆ«"""
        if model_path is None:
            # ä½¿ç”¨é»˜è®¤è·¯å¾„
            # model_path = r"C:\Users\86138\.cache\modelscope\hub\models\iic\SenseVoiceSmall"
            model_path = r"C:\project\py\agent\asr\SenseVoice\models\SenseVoiceSmall"
        self.model_path = model_path
        self.pipeline = None
        self.is_recording = False
        # åˆå§‹åŒ–å¤§æ¨¡å‹API
        self.llm_api = None
        self.selected_llm = None
        # åˆå§‹åŒ–TTSå¼•æ“
        self.tts_engine = None
        
    def init_llm_api(self, llm_type="deepseek"):
        """åˆå§‹åŒ–å¤§æ¨¡å‹API"""
        try:
            # å°è¯•å¯¼å…¥agent/llmæ¨¡å—
            llm_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'llm')
            
            # æ£€æŸ¥agent/llmç›®å½•æ˜¯å¦å­˜åœ¨
            if os.path.exists(llm_dir) and os.path.isdir(llm_dir):
                print(f"âœ… æ‰¾åˆ°LLMç›®å½•: {llm_dir}")
                
                # è®¾ç½®é»˜è®¤LLMç±»å‹
                os.environ["DEFAULT_LLM"] = llm_type
                
                # ä¼˜å…ˆæŸ¥æ‰¾è·¯ç”±å™¨æ¨¡å—
                router_file = os.path.join(llm_dir, 'llm_router.py')
                if os.path.exists(router_file):
                    print("âœ… æ‰¾åˆ°LLMè·¯ç”±å™¨æ¨¡å—")
                    # æ·»åŠ åˆ°Pythonè·¯å¾„
                    sys.path.insert(0, llm_dir)
                    # åŠ¨æ€å¯¼å…¥è·¯ç”±å™¨æ¨¡å—
                    import importlib.util
                    spec = importlib.util.spec_from_file_location("llm_router", router_file)
                    llm_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(llm_module)
                    print("âœ… æˆåŠŸå¯¼å…¥LLMè·¯ç”±å™¨æ¨¡å—")
                    self.llm_api = llm_module
                    self.selected_llm = llm_type
                    return True
                
                # æŸ¥æ‰¾å…¶ä»–LLMæ¨¡å—æ–‡ä»¶
                llm_files = [f for f in os.listdir(llm_dir) if f.endswith('.py') and not f.startswith('__')]
                if llm_files:
                    # æ ¹æ®é€‰æ‹©çš„LLMç±»å‹ç¡®å®šè¦åŠ è½½çš„æ–‡ä»¶
                    target_file = None
                    for f in llm_files:
                        if llm_type.lower() in f.lower():
                            target_file = f
                            break
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶
                    if not target_file:
                        target_file = llm_files[0]
                    
                    llm_module_name = os.path.splitext(target_file)[0]
                    print(f"âœ… æ‰¾åˆ°LLMæ¨¡å—: {target_file}")
                    
                    # æ·»åŠ åˆ°Pythonè·¯å¾„
                    sys.path.insert(0, llm_dir)
                    
                    # åŠ¨æ€å¯¼å…¥LLMæ¨¡å—
                    import importlib.util
                    spec = importlib.util.spec_from_file_location(
                        llm_module_name, 
                        os.path.join(llm_dir, target_file)
                    )
                    llm_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(llm_module)
                    print("âœ… æˆåŠŸå¯¼å…¥LLMæ¨¡å—")
                    self.llm_api = llm_module
                    self.selected_llm = llm_type
                    return True
                else:
                    print("âš ï¸ LLMç›®å½•ä¸­æœªæ‰¾åˆ°Pythonæ¨¡å—æ–‡ä»¶")
                    return False
            else:
                print("âš ï¸ æœªæ‰¾åˆ°LLMç›®å½•ï¼Œå°†ä½¿ç”¨é»˜è®¤å›å¤é€»è¾‘")
                return False
        except Exception as e:
            print(f"âš ï¸ LLMæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            print("å°†ä½¿ç”¨é»˜è®¤å›å¤é€»è¾‘")

    def init_tts_engine(self, tts_type="pyttsx3", local=False):
        """
        åˆå§‹åŒ–TTSå¼•æ“
        
        Args:
            tts_type (str): TTSå¼•æ“ç±»å‹
            local (bool): æ˜¯å¦ä½¿ç”¨æœ¬åœ°TTSå¼•æ“
        """
        try:
            if local:
                # ä½¿ç”¨æœ¬åœ°TTSå¼•æ“
                from tts.local_tts import LocalTTSEngine
                self.tts_engine = LocalTTSEngine()
                success = self.tts_engine.init_engine(tts_type)
                if not success:
                    print("âŒ æœ¬åœ°TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨æ–‡æœ¬å›å¤")
                    print("\nğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
                    print("   1. å®‰è£…åŸºç¡€TTSå¼•æ“: pip install pyttsx3")
                    print("   2. Windowsç³»ç»Ÿè¿˜éœ€è¦: pip install pypiwin32")
                    print("   3. æŸ¥çœ‹æ”¯æŒçš„å¼•æ“åˆ—è¡¨å¹¶é€‰æ‹©å¯ç”¨çš„å¼•æ“")
                    # æ˜¾ç¤ºå¯ç”¨å¼•æ“
                    available = self.tts_engine.list_available_engines()
                    if available:
                        print(f"   å¯ç”¨å¼•æ“: {', '.join(available)}")
                        print("   è¯·é‡æ–°è¿è¡Œç¨‹åºå¹¶é€‰æ‹©å¯ç”¨çš„å¼•æ“")
                    else:
                        print("   å½“å‰æ²¡æœ‰ä»»ä½•å¯ç”¨çš„TTSå¼•æ“")
                return success
            else:
                # ä½¿ç”¨åœ¨çº¿TTSå¼•æ“
                from tts.tts_engine import TTSEngine
                self.tts_engine = TTSEngine()
                return self.tts_engine.init_engine(tts_type)
        except Exception as e:
            print(f"âš ï¸ TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€çš„TTSå¼•æ“åº“")
            return False
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        print("ğŸ”§ åŠ è½½SenseVoiceæ¨¡å‹...")
        
        try:
            from modelscope.pipelines import pipeline
            from modelscope.utils.constant import Tasks
            
            self.pipeline = pipeline(
                task=Tasks.auto_speech_recognition,
                model=self.model_path,
                model_revision='v1.0.0'
            )
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def transcribe_file(self, audio_path):
        """è½¬å½•éŸ³é¢‘æ–‡ä»¶"""
        if self.pipeline is None:
            if not self.load_model():
                return None
        
        try:
            print(f"ğŸ¤ è¯†åˆ«éŸ³é¢‘: {audio_path}")
            result = self.pipeline(audio_path)
            # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
            if isinstance(result, list):
                # å¦‚æœè¿”å›æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                if len(result) > 0:
                    item = result[0]
                    if isinstance(item, dict):
                        return item.get('text', '')
                    else:
                        return str(item)
                else:
                    return ''
            elif isinstance(result, dict):
                # å¦‚æœè¿”å›æ˜¯å­—å…¸ï¼Œç›´æ¥è·å–text
                return result.get('text', '')
            else:
                # å…¶ä»–æƒ…å†µè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return str(result)
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def transcribe_bytes(self, audio_bytes, sample_rate=16000):
        """è½¬å½•éŸ³é¢‘å­—èŠ‚æ•°æ®"""
        if self.pipeline is None:
            if not self.load_model():
                return None
        
        try:
            result = self.pipeline({'input': audio_bytes, 'sample_rate': sample_rate})
            # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
            if isinstance(result, list):
                # å¦‚æœè¿”å›æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                if len(result) > 0:
                    item = result[0]
                    if isinstance(item, dict):
                        return item.get('text', '')
                    else:
                        return str(item)
                else:
                    return ''
            elif isinstance(result, dict):
                # å¦‚æœè¿”å›æ˜¯å­—å…¸ï¼Œç›´æ¥è·å–text
                return result.get('text', '')
            else:
                # å…¶ä»–æƒ…å†µè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return str(result)
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def record_audio(self, duration=5):
        """å½•åˆ¶éŸ³é¢‘"""
        # éŸ³é¢‘å‚æ•°
        FORMAT = pyaudio.paInt16
        CHANNELS = 1
        RATE = 16000
        CHUNK = 1024
        
        audio = pyaudio.PyAudio()
        
        # æ‰“å¼€éŸ³é¢‘æµ
        stream = audio.open(format=FORMAT,
                           channels=CHANNELS,
                           rate=RATE,
                           input=True,
                           frames_per_buffer=CHUNK)
        
        print(f"ğŸ™ï¸ å¼€å§‹å½•éŸ³ {duration} ç§’...")
        
        frames = []
        for _ in range(0, int(RATE / CHUNK * duration)):
            data = stream.read(CHUNK)
            frames.append(data)
        
        print("â¹ï¸ å½•éŸ³ç»“æŸ")
        
        # åœæ­¢å¹¶å…³é—­æµ
        stream.stop_stream()
        stream.close()
        audio.terminate()
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            wf = wave.open(tmp_file.name, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(audio.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()
            return tmp_file.name
    
    def record_audio_vad(self, silence_threshold=500, silence_duration=2):
        """ä½¿ç”¨VADå½•åˆ¶éŸ³é¢‘ï¼Œæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨å¹¶åœ¨åœé¡¿æŒ‡å®šæ—¶é—´åç»“æŸå½•åˆ¶"""
        # éŸ³é¢‘å‚æ•°
        FORMAT = pyaudio.paInt16
        CHANNELS = 1
        RATE = 16000
        CHUNK = 1024
        SILENCE_CHUNKS = int(silence_duration * RATE / CHUNK)  # é™éŸ³å—æ•°é˜ˆå€¼
        
        audio = pyaudio.PyAudio()
        
        # æ‰“å¼€éŸ³é¢‘æµ
        stream = audio.open(format=FORMAT,
                           channels=CHANNELS,
                           rate=RATE,
                           input=True,
                           frames_per_buffer=CHUNK)
        
        print("ğŸ™ï¸ å¼€å§‹å½•éŸ³ (VADæ¨¡å¼)...")
        print("ğŸ—£ï¸ è¯·è¯´è¯...")
        
        frames = []
        silent_chunks = 0
        audio_started = False
        
        while True:
            data = stream.read(CHUNK)
            frames.append(data)
            
            # è®¡ç®—éŸ³é¢‘èƒ½é‡ï¼ˆå‡æ–¹æ ¹ï¼‰
            audio_data = np.frombuffer(data, dtype=np.int16)
            rms = np.sqrt(np.mean(audio_data**2))
            
            # æ£€æµ‹æ˜¯å¦æ˜¯é™éŸ³
            is_silent = rms < silence_threshold
            
            if not audio_started:
                # è¿˜æœªæ£€æµ‹åˆ°è¯­éŸ³
                if not is_silent:
                    audio_started = True
                    print("ğŸ”Š æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨...")
                    silent_chunks = 0
                else:
                    # è¿˜æ²¡å¼€å§‹è¯´è¯ï¼Œä¿ç•™ä¸€äº›å‰ç½®é™éŸ³
                    if len(frames) > 20:  # ä¿ç•™çº¦0.25ç§’çš„å‰ç½®é™éŸ³
                        frames.pop(0)
            else:
                # å·²ç»å¼€å§‹å½•éŸ³
                if is_silent:
                    silent_chunks += 1
                    # å¦‚æœé™éŸ³æ—¶é—´è¾¾åˆ°é˜ˆå€¼ï¼Œåˆ™ç»“æŸå½•éŸ³
                    if silent_chunks > SILENCE_CHUNKS:
                        print("â¹ï¸ æ£€æµ‹åˆ°åœé¡¿ï¼Œå½•éŸ³ç»“æŸ")
                        break
                else:
                    silent_chunks = 0
        
        # åœæ­¢å¹¶å…³é—­æµ
        stream.stop_stream()
        stream.close()
        audio.terminate()
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            wf = wave.open(tmp_file.name, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(audio.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()
            return tmp_file.name
    
    def live_transcribe(self):
        """å®æ—¶è¯­éŸ³è¯†åˆ«"""
        print("ğŸ™ï¸ å¼€å§‹å®æ—¶è¯­éŸ³è¯†åˆ« (æŒ‰ Ctrl+C åœæ­¢)")
        try:
            while True:
                # å½•åˆ¶3ç§’éŸ³é¢‘
                audio_file = self.record_audio(duration=3)
                try:
                    # è¯†åˆ«éŸ³é¢‘
                    text = self.transcribe_file(audio_file)
                    if text:
                        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")
                finally:
                    # ç¡®ä¿åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(audio_file):
                        os.unlink(audio_file)
        except KeyboardInterrupt:
            print("\nâ¹ï¸ å®æ—¶è¯­éŸ³è¯†åˆ«å·²åœæ­¢")
            
    def chat_mode(self):
        """å¯¹è¯æ¨¡å¼"""
        print("ğŸ’¬ è¿›å…¥å¯¹è¯æ¨¡å¼ (è¯´'æ‹œæ‹œ'å¯è¿”å›é€‰é¡¹ç•Œé¢ï¼ŒæŒ‰ Ctrl+C é€€å‡º)")
        print("ğŸ—£ï¸ è¯·è¯´è¯...")

        # ç®€å•çš„å¯¹è¯é€»è¾‘ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥æ¥å…¥å¤§æ¨¡å‹API
        conversation_history = []
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ”§ è°ƒè¯•: å¯¹è¯å¼€å§‹æ—¶TTSå¼•æ“çŠ¶æ€ = {self.tts_engine is not None}")
        if self.tts_engine:
            print(f"ğŸ”§ è°ƒè¯•: TTSå¼•æ“ç±»å‹ = {getattr(self.tts_engine, 'engine_type', 'æœªçŸ¥')}")

        try:
            while True:
                # ä½¿ç”¨VADå½•åˆ¶éŸ³é¢‘
                audio_file = self.record_audio_vad(silence_duration=2)
                try:
                    # è¯†åˆ«éŸ³é¢‘
                    user_input = self.transcribe_file(audio_file)

                    if user_input and not user_input.startswith("<|nospeech|>"):
                        print(f"ğŸ‘¤ ä½ è¯´: {user_input}")
                        
                        # è°ƒè¯•ä¿¡æ¯
                        print(f"ğŸ”§ è°ƒè¯•: å‡†å¤‡æ£€æŸ¥å…³é”®è¯")
                        
                        # æ£€æŸ¥é€€å‡ºå…³é”®è¯
                        exit_keywords = ["ä½ æ»šå§", "ä½ èµ¶ç´§å»æ­»å§", "æ»šå§", "æ»š", "æ»šå•Š", "é€€å‡º", "é€€å‡ºå§", "å…³æœºå§"]
                        if any(keyword in user_input for keyword in exit_keywords):
                            print("ğŸ‘‹ å¥½çš„ï¼Œå†è§ï¼")
                            if self.tts_engine:
                                print("ğŸ”Š æ­£åœ¨æ’­æ”¾é€€å‡ºè¯­éŸ³")
                                self.tts_engine.speak("å¥½çš„ï¼Œå†è§ï¼")
                            break
                        
                        # æ£€æŸ¥è¿”å›é€‰é¡¹ç•Œé¢å…³é”®è¯
                        elif "æ‹œæ‹œ" in user_input:
                            print("ğŸ‘‹ å¥½çš„ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†èŠï¼")
                            if self.tts_engine:
                                print("ğŸ”Š æ­£åœ¨æ’­æ”¾è¿”å›è¯­éŸ³")
                                self.tts_engine.speak("å¥½çš„ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†èŠï¼")
                            # è¿”å›Trueè¡¨ç¤ºéœ€è¦å›åˆ°é€‰é¡¹ç•Œé¢
                            return True

                        # ä½¿ç”¨å¤§æ¨¡å‹APIç”Ÿæˆå›å¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        print("ğŸ¤– æ­£åœ¨ç”Ÿæˆå›å¤...")
                        response = self.generate_llm_response(user_input, conversation_history)
                        print(f"ğŸ¤– å›å¤: {response}")

                        # ä½¿ç”¨TTSæ’­æ”¾å›å¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        print(f"ğŸ”§ sensevoice_demo TTSå¼•æ“çŠ¶æ€: {self.tts_engine is not None}")
                        if self.tts_engine:
                            print(f"ğŸ”Š æ’­æ”¾å›å¤: {response}")
                            success = self.tts_engine.speak(response)
                            print(f"ğŸ”§ TTSæ’­æ”¾ç»“æœ: {success}")
                        else:
                            print("ğŸ”‡ TTSå¼•æ“æœªåˆå§‹åŒ–ï¼Œè·³è¿‡è¯­éŸ³æ’­æ”¾")

                        # å°†å¯¹è¯åŠ å…¥å†å²è®°å½•
                        conversation_history.append({"user": user_input, "bot": response})
                        # é™åˆ¶å†å²è®°å½•é•¿åº¦
                        if len(conversation_history) > 10:
                            conversation_history.pop(0)
                finally:
                    # ç¡®ä¿åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(audio_file):
                        os.unlink(audio_file)
                        
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å¯¹è¯ç»“æŸï¼Œå†è§ï¼")
        # è¿”å›Falseè¡¨ç¤ºæ˜¯é€šè¿‡Ctrl+Cé€€å‡ºçš„
        return False
    
    def generate_llm_response(self, user_input, conversation_history):
        """ä½¿ç”¨å¤§æ¨¡å‹APIç”Ÿæˆå›å¤"""
        # å¦‚æœLLM APIå¯ç”¨ï¼Œä½¿ç”¨å®ƒç”Ÿæˆå›å¤
        if self.llm_api is not None:
            try:
                # æ£€æŸ¥LLMæ¨¡å—æ˜¯å¦æœ‰generate_responseæ–¹æ³•
                if hasattr(self.llm_api, 'generate_response'):
                    # æ„é€ å¯¹è¯å†å²
                    history = []
                    for exchange in conversation_history:
                        history.append({"role": "user", "content": exchange["user"]})
                        history.append({"role": "assistant", "content": exchange["bot"]})
                    
                    # è°ƒç”¨LLM API
                    response = self.llm_api.generate_response(user_input, history)
                    return response
                else:
                    print("âš ï¸ LLMæ¨¡å—ç¼ºå°‘generate_responseæ–¹æ³•ï¼Œä½¿ç”¨é»˜è®¤å›å¤é€»è¾‘")
                    return self.generate_response(user_input, conversation_history)
            except Exception as e:
                print(f"âš ï¸ LLM APIè°ƒç”¨å¤±è´¥: {e}")
                # å›é€€åˆ°é»˜è®¤å›å¤é€»è¾‘
                return self.generate_response(user_input, conversation_history)
        else:
            # ä½¿ç”¨é»˜è®¤å›å¤é€»è¾‘
            return self.generate_response(user_input, conversation_history)
    
    def generate_response(self, user_input, conversation_history):
        """ç”Ÿæˆå›å¤ - ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”ç”¨ä¸­å¯æ¥å…¥å¤§æ¨¡å‹"""
        # è¿™é‡Œæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„å›å¤é€»è¾‘ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥æ›¿æ¢ä¸ºå¤§æ¨¡å‹APIè°ƒç”¨
        user_input = user_input.lower()
        
        if "ä½ å¥½" in user_input or "hello" in user_input:
            return "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
        elif "è°¢è°¢" in user_input or "thank" in user_input:
            return "ä¸å®¢æ°”ï¼è¿˜æœ‰å…¶ä»–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ"
        elif "å†è§" in user_input or "bye" in user_input:
            return "å†è§ï¼æœŸå¾…ä¸‹æ¬¡ä¸ä½ äº¤æµï¼"
        elif "å¤©æ°”" in user_input:
            return "æˆ‘æ— æ³•è·å–å®æ—¶å¤©æ°”ä¿¡æ¯ï¼Œå»ºè®®ä½ æŸ¥çœ‹å¤©æ°”é¢„æŠ¥åº”ç”¨ã€‚"
        elif "åå­—" in user_input or "ä½ æ˜¯è°" in user_input:
            return "æˆ‘æ˜¯åŸºäºSenseVoiceçš„è¯­éŸ³å¯¹è¯åŠ©æ‰‹ã€‚"
        else:
            # åŸºäºå†å²å¯¹è¯ç”Ÿæˆå›å¤
            if conversation_history:
                last_exchange = conversation_history[-1]
                if "ä½ å¥½" in last_exchange["user"]:
                    return "å¾ˆé«˜å…´è§åˆ°ä½ ï¼ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿ"
                elif "å¤©æ°”" in last_exchange["user"]:
                    return "è™½ç„¶æˆ‘ä¸çŸ¥é“å…·ä½“å¤©æ°”ï¼Œä½†æˆ‘å¸Œæœ›æ˜¯ä¸ªå¥½å¤©æ°”ï¼"
            
            # é»˜è®¤å›å¤
            responses = [
                "å¾ˆæœ‰è¶£ï¼èƒ½å‘Šè¯‰æˆ‘æ›´å¤šå—ï¼Ÿ",
                "æˆ‘æ˜ç™½äº†ï¼Œè¿˜æœ‰åˆ«çš„å—ï¼Ÿ",
                "å¥½çš„ï¼Œæˆ‘è®°ä½äº†ã€‚",
                "è¿™å¾ˆæœ‰æ„æ€å‘¢ï¼",
                "è°¢è°¢ä½ åˆ†äº«è¿™äº›ä¿¡æ¯ã€‚"
            ]
            import random
            return random.choice(responses)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # 1. åˆ›å»ºè¯†åˆ«å™¨
    asr = SenseVoiceASR()
    
    # 2. åŠ è½½æ¨¡å‹
    if asr.load_model():
        print("ğŸ¯ SenseVoiceå‡†å¤‡å°±ç»ªï¼")
        
        # å¾ªç¯æ˜¾ç¤ºèœå•ç›´åˆ°ç”¨æˆ·é€‰æ‹©é€€å‡º
        while True:
            # 3. æä¾›é€‰é¡¹
            print("\nè¯·é€‰æ‹©æ“ä½œ:")
            print("1. è¯†åˆ«æµ‹è¯•æ–‡ä»¶")
            print("2. å®æ—¶éº¦å…‹é£è¯­éŸ³è¯†åˆ«")
            print("3. è¯­éŸ³å¯¹è¯æ¨¡å¼")
            print("4. è¯­éŸ³å¯¹è¯æ¨¡å¼ï¼ˆé€‰æ‹©LLMï¼‰")
            print("5. è¯­éŸ³å¯¹è¯æ¨¡å¼ï¼ˆé€‰æ‹©LLMå’Œåœ¨çº¿TTSï¼‰")
            print("6. è¯­éŸ³å¯¹è¯æ¨¡å¼ï¼ˆé€‰æ‹©LLMå’Œæœ¬åœ°TTSï¼‰")
            
            choice = input("è¯·è¾“å…¥é€‰é¡¹ (1, 2, 3, 4, 5 æˆ– 6): ").strip()
            
            if choice == "1":
                # è¯†åˆ«æµ‹è¯•æ–‡ä»¶
                test_file = "./SenseVoice/models/SenseVoiceSmall/example/zh.mp3"
                if os.path.exists(test_file):
                    text = asr.transcribe_file(test_file)
                    if text:
                        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")
                else:
                    print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
                    print("ğŸ’¡ è¯·å…ˆåˆ›å»ºä¸€ä¸ªtest_audio.wavæ–‡ä»¶")
                    
            elif choice == "2":
                # å®æ—¶è¯­éŸ³è¯†åˆ«
                asr.live_transcribe()
                
            elif choice == "3":
                # å¯¹è¯æ¨¡å¼ - ä½¿ç”¨é»˜è®¤LLM
                asr.init_llm_api()
                back_to_menu = asr.chat_mode()
                # å¦‚æœæ˜¯é€šè¿‡"æ‹œæ‹œ"é€€å‡ºï¼Œåˆ™é‡æ–°æ˜¾ç¤ºèœå•
                if back_to_menu:
                    continue
                # å¦åˆ™æ˜¯é€šè¿‡Ctrl+Cé€€å‡ºï¼Œç»“æŸç¨‹åº
                else:
                    break
                
            elif choice == "4":
                # å¯¹è¯æ¨¡å¼ - é€‰æ‹©LLM
                print("\nè¯·é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹:")
                print("1. DeepSeek")
                print("2. è±†åŒ…(Doubao)")
                print("3. é€šä¹‰åƒé—®(Qwen)")
                
                llm_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1, 2 æˆ– 3): ").strip()
                llm_type = "deepseek"
                
                if llm_choice == "1":
                    llm_type = "deepseek"
                elif llm_choice == "2":
                    llm_type = "doubao"
                elif llm_choice == "3":
                    llm_type = "qwen"
                else:
                    print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: DeepSeek")
                    
                asr.init_llm_api(llm_type)
                if asr.selected_llm:
                    print(f"âœ… å·²é€‰æ‹© {asr.selected_llm} æ¨¡å‹")
                back_to_menu = asr.chat_mode()
                # å¦‚æœæ˜¯é€šè¿‡"æ‹œæ‹œ"é€€å‡ºï¼Œåˆ™é‡æ–°æ˜¾ç¤ºèœå•
                if back_to_menu:
                    continue
                # å¦åˆ™æ˜¯é€šè¿‡Ctrl+Cé€€å‡ºï¼Œç»“æŸç¨‹åº
                else:
                    break
                
            elif choice == "5":
                # å¯¹è¯æ¨¡å¼ - é€‰æ‹©LLMå’Œåœ¨çº¿TTS
                # é€‰æ‹©LLM
                print("\nè¯·é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹:")
                print("1. DeepSeek")
                print("2. è±†åŒ…(Doubao)")
                print("3. é€šä¹‰åƒé—®(Qwen)")
                
                llm_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1, 2 æˆ– 3): ").strip()
                llm_type = "deepseek"
                
                if llm_choice == "1":
                    llm_type = "deepseek"
                elif llm_choice == "2":
                    llm_type = "doubao"
                elif llm_choice == "3":
                    llm_type = "qwen"
                else:
                    print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: DeepSeek")
                    
                asr.init_llm_api(llm_type)
                if asr.selected_llm:
                    print(f"âœ… å·²é€‰æ‹© {asr.selected_llm} æ¨¡å‹")
                
                # é€‰æ‹©åœ¨çº¿TTS
                print("\nè¯·é€‰æ‹©åœ¨çº¿TTSå¼•æ“:")
                print("1. pyttsx3 (ç¦»çº¿, å…è´¹, è·¨å¹³å°)")
                print("2. ç™¾åº¦TTS (åœ¨çº¿, éœ€APIå¯†é’¥)")
                print("3. é˜¿é‡Œäº‘TTS (åœ¨çº¿, éœ€APIå¯†é’¥)")
                
                tts_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1, 2 æˆ– 3): ").strip()
                tts_type = "pyttsx3"
                
                if tts_choice == "1":
                    tts_type = "pyttsx3"
                elif tts_choice == "2":
                    tts_type = "baidu"
                elif tts_choice == "3":
                    tts_type = "ali"
                else:
                    print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤TTSå¼•æ“: pyttsx3")
                    
                if asr.init_tts_engine(tts_type, local=False):
                    print(f"âœ… å·²é€‰æ‹© {tts_type} åœ¨çº¿TTSå¼•æ“")
                else:
                    print("âŒ TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨æ–‡æœ¬å›å¤")
                
                back_to_menu = asr.chat_mode()
                # å¦‚æœæ˜¯é€šè¿‡"æ‹œæ‹œ"é€€å‡ºï¼Œåˆ™é‡æ–°æ˜¾ç¤ºèœå•
                if back_to_menu:
                    continue
                # å¦åˆ™æ˜¯é€šè¿‡Ctrl+Cé€€å‡ºï¼Œç»“æŸç¨‹åº
                else:
                    break
                
            elif choice == "6":
                # å¯¹è¯æ¨¡å¼ - é€‰æ‹©LLMå’Œæœ¬åœ°TTS
                # é€‰æ‹©LLM
                print("\nè¯·é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹:")
                print("1. DeepSeek")
                print("2. è±†åŒ…(Doubao)")
                print("3. é€šä¹‰åƒé—®(Qwen)")
                
                llm_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1, 2 æˆ– 3): ").strip()
                llm_type = "deepseek"
                
                if llm_choice == "1":
                    llm_type = "deepseek"
                elif llm_choice == "2":
                    llm_type = "doubao"
                elif llm_choice == "3":
                    llm_type = "qwen"
                else:
                    print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: DeepSeek")
                    
                asr.init_llm_api(llm_type)
                if asr.selected_llm:
                    print(f"âœ… å·²é€‰æ‹© {asr.selected_llm} æ¨¡å‹")
                
                # é€‰æ‹©æœ¬åœ°TTS
                print("\nè¯·é€‰æ‹©æœ¬åœ°TTSå¼•æ“:")
                print("1. MeloTTS (æ¨èï¼Œæ”¯æŒä¸­è‹±æ··åˆ)")
                print("2. PaddleSpeech (ç™¾åº¦å¼€æºï¼Œä¸­æ–‡ä¼˜åŒ–)")
                print("3. Coqui TTS (å¤šè¯­è¨€æ”¯æŒ)")
                print("4. IndexTTS (Bç«™å¼€æºï¼Œé«˜è´¨é‡è¯­éŸ³)")
                print("5. Edge-TTS (å¾®è½¯è¯­éŸ³ï¼Œéœ€è¦ç½‘ç»œè¿æ¥)")
                print("6. pyttsx3 (ç³»ç»Ÿè¯­éŸ³ï¼Œè½»é‡çº§ï¼Œæ— éœ€ç½‘ç»œ)")
                
                tts_choice = input("è¯·è¾“å…¥é€‰é¡¹ (1, 2, 3, 4, 5 æˆ– 6): ").strip()
                tts_type = "melotts"
                
                if tts_choice == "1":
                    tts_type = "melotts"
                elif tts_choice == "2":
                    tts_type = "paddlespeech"
                elif tts_choice == "3":
                    tts_type = "coqui"
                elif tts_choice == "4":
                    tts_type = "indextts"
                elif tts_choice == "5":
                    tts_type = "edge-tts"
                elif tts_choice == "6":
                    tts_type = "pyttsx3"
                else:
                    print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤æœ¬åœ°TTSå¼•æ“: MeloTTS")
                    
                if asr.init_tts_engine(tts_type, local=True):
                    print(f"âœ… å·²é€‰æ‹© {tts_type} æœ¬åœ°TTSå¼•æ“")
                else:
                    print("âŒ æœ¬åœ°TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨æ–‡æœ¬å›å¤")
                
                back_to_menu = asr.chat_mode()
                # å¦‚æœæ˜¯é€šè¿‡"æ‹œæ‹œ"é€€å‡ºï¼Œåˆ™é‡æ–°æ˜¾ç¤ºèœå•
                if back_to_menu:
                    continue
                # å¦åˆ™æ˜¯é€šè¿‡Ctrl+Cé€€å‡ºï¼Œç»“æŸç¨‹åº
                else:
                    break
                
            else:
                print("âŒ æ— æ•ˆé€‰é¡¹")

    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨SenseVoiceè¯­éŸ³è¯†åˆ«ç³»ç»Ÿï¼Œå†è§ï¼")
