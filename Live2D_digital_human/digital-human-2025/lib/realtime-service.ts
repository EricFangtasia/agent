'use client';

// æ¨¡æ‹Ÿ RealtimeClient ç±»å‹å®šä¹‰
interface RealtimeClient {
  apiKey?: string;
  dangerouslyAllowAPIKeyInBrowser?: boolean;
  connect: () => Promise<void>;
  disconnect: () => void;
  updateSession: (options: any) => Promise<void>;
  on: (event: string, handler: (data: any) => void) => void;
  appendInputAudio: (audio: string) => void;
  createResponse: () => void;
  sendUserMessageContent: (content: any[]) => void;
  cancelResponse: () => void;
}

// è‡ªå®šä¹‰å®ç°
class CustomRealtimeClient implements RealtimeClient {
  apiKey?: string;
  dangerouslyAllowAPIKeyInBrowser?: boolean;
  
  constructor(options?: { apiKey?: string; dangerouslyAllowAPIKeyInBrowser?: boolean }) {
    this.apiKey = options?.apiKey;
    this.dangerouslyAllowAPIKeyInBrowser = options?.dangerouslyAllowAPIKeyInBrowser;
  }
  
  async connect(): Promise<void> {
    // æ¨¡æ‹Ÿè¿æ¥è¿‡ç¨‹
    console.log('Custom Realtime Client connected');
  }
  
  disconnect(): void {
    console.log('Custom Realtime Client disconnected');
  }
  
  async updateSession(options: any): Promise<void> {
    console.log('Session updated:', options);
  }
  
  on(event: string, handler: (data: any) => void): void {
    // å®ç°äº‹ä»¶ç›‘å¬æœºåˆ¶
    console.log(`Event listener registered for: ${event}`);
  }
  
  appendInputAudio(audio: string): void {
    console.log('Input audio appended:', audio.substring(0, 20) + '...');
  }
  
  createResponse(): void {
    console.log('Creating response');
  }
  
  sendUserMessageContent(content: any[]): void {
    console.log('Sending user message:', content);
  }
  
  cancelResponse(): void {
    console.log('Response cancelled');
  }
}

import { useDigitalHumanStore, Message } from './store';
import { SimplifiedAIService } from './simplified-ai-service';

export class RealtimeService {
  private client: RealtimeClient | null = null;
  private audioContext: AudioContext | null = null;
  private mediaRecorder: MediaRecorder | null = null;
  private recordingStream: MediaStream | null = null;
  private recognition: any = null;
  private simplifiedAIService: SimplifiedAIService;

  constructor() {
    if (typeof window !== 'undefined') {
      this.audioContext = new AudioContext();
      this.simplifiedAIService = SimplifiedAIService.getInstance();
      this.initializeSpeechRecognition();
    }
  }

  /**
   * åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«åŠŸèƒ½
   */
  private initializeSpeechRecognition() {
    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒ Web Speech API
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      this.recognition = new SpeechRecognition();
      this.recognition.continuous = true;
      this.recognition.interimResults = true;
      this.recognition.lang = 'zh-CN'; // è®¾ç½®ä¸ºä¸­æ–‡è¯†åˆ«
      
      this.recognition.onresult = (event: any) => {
        let transcript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            transcript += event.results[i][0].transcript;
          }
        }
        
        if (transcript) {
          console.log('ç”¨æˆ·è¯´:', transcript);
          useDigitalHumanStore.getState().addMessage({
            role: 'user',
            content: transcript,
          });
          
          // é€šè¿‡ç«å±±å¼•æ“è·å–AIå›å¤
          this.getVolcEngineResponse(transcript);
        }
      };
      
      this.recognition.onerror = (event: any) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
      };
    }
  }

  /**
   * é€šè¿‡ç®€åŒ–ç‰ˆAIæœåŠ¡è·å–AIå›å¤
   */
  private async getSimplifiedAIResponse(userInput: string) {
    try {
      // è·å–å½“å‰å¯¹è¯å†å²
      const messages = [...useDigitalHumanStore.getState().messages];
      // åªä¿ç•™æœ€è¿‘çš„10æ¡æ¶ˆæ¯ä»¥é¿å…è¶…å‡ºAPIé™åˆ¶
      const recentMessages = messages.slice(-10);
      
      // æ·»åŠ ç”¨æˆ·çš„æ–°æ¶ˆæ¯
      const allMessages = [...recentMessages, { role: 'user', content: userInput }] as Message[];
      
      // è°ƒç”¨ç®€åŒ–ç‰ˆAIæœåŠ¡
      const aiResponse = await this.simplifiedAIService.sendMessage(allMessages);
      
      console.log('AIå›å¤:', aiResponse);
      useDigitalHumanStore.getState().addMessage({
        role: 'assistant',
        content: aiResponse,
      });
      
      // ä½¿ç”¨ Web Speech API æ’­æ”¾å›å¤
      this.speak(aiResponse);
    } catch (error) {
      console.error('è·å–AIå›å¤å¤±è´¥:', error);
      
      // å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›å¤
      const fallbackResponse = 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œç¨åå†èŠå§ã€‚';
      useDigitalHumanStore.getState().addMessage({
        role: 'assistant',
        content: fallbackResponse,
      });
      
      this.speak(fallbackResponse);
    }
  }

  /**
   * ä½¿ç”¨ Web Speech API æœ—è¯»æ–‡æœ¬
   */
  private speak(text: string) {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'zh-CN';
      utterance.rate = 1.0;
      utterance.pitch = 1.0;
      
      utterance.onstart = () => {
        console.log('å¼€å§‹æ’­æ”¾è¯­éŸ³');
        useDigitalHumanStore.getState().setSpeaking(true);
        useDigitalHumanStore.getState().setMouthOpenness(0.8);
      };
      
      utterance.onend = () => {
        console.log('è¯­éŸ³æ’­æ”¾ç»“æŸ');
        useDigitalHumanStore.getState().setSpeaking(false);
        useDigitalHumanStore.getState().setMouthOpenness(0);
      };
      
      // æ¨¡æ‹Ÿå£å‹åŒæ­¥
      this.simulateLipSync();
      
      speechSynthesis.speak(utterance);
    }
  }

  /**
   * æ¨¡æ‹Ÿå£å‹åŒæ­¥
   */
  private simulateLipSync() {
    let frame = 0;
    const totalFrames = 60; // æ¨¡æ‹Ÿ60å¸§çš„åŠ¨ç”»
    
    const animate = () => {
      if (frame < totalFrames && useDigitalHumanStore.getState().isSpeaking) {
        // éšæœºåŠ¨ç”»æ•ˆæœ
        const openness = 0.3 + Math.random() * 0.7;
        useDigitalHumanStore.getState().setMouthOpenness(openness);
        
        frame++;
        requestAnimationFrame(animate);
      } else if (frame >= totalFrames) {
        useDigitalHumanStore.getState().setMouthOpenness(0);
      }
    };
    
    animate();
  }

  /**
   * åˆå§‹åŒ–è¿æ¥
   */
  async connect(apiKey: string) {
    // åˆå§‹åŒ–ç®€åŒ–ç‰ˆAIæœåŠ¡
    await this.simplifiedAIService.connect(apiKey);

    // ä½¿ç”¨è‡ªå®šä¹‰å®ç°
    this.client = new CustomRealtimeClient({
      apiKey: apiKey,
      dangerouslyAllowAPIKeyInBrowser: true,
    });

    // æ¨¡æ‹Ÿé…ç½®ä¼šè¯å‚æ•°
    await this.client.updateSession({
      instructions: `ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€æ´»æ³¼çš„AIåŠ©æ‰‹ï¼Œåå­—å«å°è‰¾ã€‚
      è¯·ç”¨ç®€æ´ã€è‡ªç„¶çš„æ–¹å¼å›å¤ï¼Œå°±åƒåœ¨å’Œæœ‹å‹èŠå¤©ä¸€æ ·ã€‚
      å›å¤è¦ç®€çŸ­ï¼ˆ1-2å¥è¯ï¼‰ï¼Œä¸è¦é•¿ç¯‡å¤§è®ºã€‚
      é€‚å½“ä½¿ç”¨è¯­æ°”è¯è®©å¯¹è¯æ›´ç”ŸåŠ¨ã€‚`,
      voice: 'alloy',
      input_audio_format: 'pcm16',
      output_audio_format: 'pcm16',
      input_audio_transcription: {
        model: 'whisper-1',
      },
      turn_detection: {
        type: 'server_vad',
        threshold: 0.5,
        prefix_padding_ms: 300,
        silence_duration_ms: 500,
      },
      temperature: 0.8,
      max_response_output_tokens: 4096,
    });

    // è¿æ¥
    await this.client.connect();
    
    this.setupEventHandlers();
    useDigitalHumanStore.getState().setConnected(true);
    
    console.log('âœ… ç®€åŒ–ç‰ˆ AI æœåŠ¡å·²è¿æ¥');
  }

  /**
   * è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
   */
  private setupEventHandlers() {
    if (!this.client) return;

    // æ³¨å†Œå„ç§äº‹ä»¶å¤„ç†å™¨ï¼ˆæ¨¡æ‹Ÿï¼‰
    (this.client as any).on('conversation.item.input_audio_transcription.completed', (event: any) => {
      console.log('ç”¨æˆ·è¯´:', event.transcript);
      useDigitalHumanStore.getState().addMessage({
        role: 'user',
        content: event.transcript,
      });
    });

    (this.client as any).on('response.text.delta', (event: any) => {
      console.log('AIå›å¤ç‰‡æ®µ:', event.delta);
    });

    (this.client as any).on('response.text.done', (event: any) => {
      console.log('AIå›å¤å®Œæˆ:', event.text);
      useDigitalHumanStore.getState().addMessage({
        role: 'assistant',
        content: event.text,
      });
    });

    (this.client as any).on('response.audio.delta', (event: any) => {
      this.handleAudioDelta(event.delta);
    });

    (this.client as any).on('response.audio.done', () => {
      console.log('âœ… AIè¯­éŸ³æ’­æ”¾å®Œæˆ');
      useDigitalHumanStore.getState().setSpeaking(false);
      useDigitalHumanStore.getState().setMouthOpenness(0);
    });

    (this.client as any).on('error', (error: any) => {
      console.error('âŒ Realtime APIé”™è¯¯:', error);
    });
  }

  /**
   * å¤„ç†éŸ³é¢‘æ•°æ®å¹¶è¿›è¡Œå£å‹åŒæ­¥
   */
  private async handleAudioDelta(audioData: string) {
    if (!this.audioContext) return;

    useDigitalHumanStore.getState().setSpeaking(true);

    try {
      // è§£ç base64éŸ³é¢‘æ•°æ®
      const binaryString = atob(audioData);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      // è½¬æ¢ä¸ºAudioBuffer
      const audioBuffer = await this.audioContext.decodeAudioData(bytes.buffer);
      
      // æ’­æ”¾éŸ³é¢‘
      const source = this.audioContext.createBufferSource();
      source.buffer = audioBuffer;
      
      // åˆ›å»ºåˆ†æå™¨ç”¨äºå£å‹åŒæ­¥
      const analyser = this.audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      analyser.connect(this.audioContext.destination);
      
      source.start();

      // å®æ—¶åˆ†æéŸ³é‡æ§åˆ¶å£å‹
      this.analyzeAudioForLipSync(analyser);
      
    } catch (error) {
      console.error('éŸ³é¢‘å¤„ç†é”™è¯¯:', error);
    }
  }

  /**
   * åˆ†æéŸ³é¢‘å¹¶æ§åˆ¶å£å‹
   */
  private analyzeAudioForLipSync(analyser: AnalyserNode) {
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    
    const analyze = () => {
      analyser.getByteFrequencyData(dataArray);
      
      // è®¡ç®—å¹³å‡éŸ³é‡
      const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
      const normalizedVolume = Math.min(average / 128, 1);
      
      // æ›´æ–°å˜´å·´å¼€åˆåº¦
      useDigitalHumanStore.getState().setMouthOpenness(normalizedVolume);
      
      // å¦‚æœè¿˜åœ¨æ’­æ”¾ï¼Œç»§ç»­åˆ†æ
      if (useDigitalHumanStore.getState().isSpeaking) {
        requestAnimationFrame(analyze);
      }
    };
    
    analyze();
  }

  /**
   * å¼€å§‹å½•éŸ³
   */
  async startRecording() {
    try {
      // å¦‚æœæµè§ˆå™¨æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œç›´æ¥å¯åŠ¨
      if (this.recognition) {
        this.recognition.start();
        useDigitalHumanStore.getState().setRecording(true);
        console.log('ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆä½¿ç”¨Web Speech APIï¼‰');
      } else {
        // å¦åˆ™ä½¿ç”¨ä¼ ç»Ÿå½•éŸ³æ–¹å¼
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          } 
        });
        
        this.recordingStream = stream;
        this.mediaRecorder = new MediaRecorder(stream, {
          mimeType: 'audio/webm',
        });

        this.mediaRecorder.ondataavailable = async (event) => {
          if (event.data.size > 0 && this.client) {
            // å°†éŸ³é¢‘å‘é€åˆ°æ¨¡æ‹ŸAPI
            const arrayBuffer = await event.data.arrayBuffer();
            const base64 = this.arrayBufferToBase64(arrayBuffer);
            
            (this.client as any).appendInputAudio(base64);
          }
        };

        // æ¯100mså‘é€ä¸€æ¬¡éŸ³é¢‘æ•°æ®
        this.mediaRecorder.start(100);
        useDigitalHumanStore.getState().setRecording(true);
        
        console.log('ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆä½¿ç”¨MediaRecorderï¼‰');
      }
    } catch (error) {
      console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
    }
  }

  /**
   * åœæ­¢å½•éŸ³
   */
  stopRecording() {
    if (this.recognition) {
      this.recognition.stop();
      useDigitalHumanStore.getState().setRecording(false);
      console.log('ğŸ›‘ åœæ­¢å½•éŸ³ï¼ˆä½¿ç”¨Web Speech APIï¼‰');
    } else if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
      this.mediaRecorder.stop();
      this.recordingStream?.getTracks().forEach(track => track.stop());
      useDigitalHumanStore.getState().setRecording(false);
      
      // æäº¤éŸ³é¢‘ï¼Œè§¦å‘AIå“åº”
      (this.client as any)?.createResponse();
      
      console.log('ğŸ›‘ åœæ­¢å½•éŸ³ï¼ˆä½¿ç”¨MediaRecorderï¼‰');
    }
  }

  /**
   * å‘é€æ–‡æœ¬æ¶ˆæ¯
   */
  async sendText(text: string) {
    if (!this.simplifiedAIService.isConnectedToService()) {
      console.error('ç®€åŒ–ç‰ˆAIæœåŠ¡æœªåˆå§‹åŒ–');
      return;
    }

    useDigitalHumanStore.getState().addMessage({
      role: 'user',
      content: text,
    });

    // é€šè¿‡ç®€åŒ–ç‰ˆAIæœåŠ¡è·å–AIå›å¤
    this.getSimplifiedAIResponse(text);
  }

  /**
   * æ‰“æ–­AIè¯´è¯
   */
  interrupt() {
    if (this.client) {
      (this.client as any).cancelResponse();
      useDigitalHumanStore.getState().setSpeaking(false);
      useDigitalHumanStore.getState().setMouthOpenness(0);
      
      // å¦‚æœæœ‰æ­£åœ¨è¿›è¡Œçš„è¯­éŸ³åˆæˆï¼Œåœæ­¢å®ƒ
      if ('speechSynthesis' in window) {
        speechSynthesis.cancel();
      }
    }
  }

  /**
   * æ–­å¼€è¿æ¥
   */
  disconnect() {
    this.stopRecording();
    this.client?.disconnect();
    this.simplifiedAIService.disconnect();
    this.audioContext?.close();
    useDigitalHumanStore.getState().setConnected(false);
    console.log('ğŸ‘‹ å·²æ–­å¼€è¿æ¥');
  }

  /**
   * å·¥å…·å‡½æ•°ï¼šArrayBufferè½¬Base64
   */
  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.length; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }
}

// å•ä¾‹å®ä¾‹
let realtimeServiceInstance: RealtimeService | null = null;

export function getRealtimeService(): RealtimeService {
  if (!realtimeServiceInstance) {
    realtimeServiceInstance = new RealtimeService();
  }
  return realtimeServiceInstance;
}